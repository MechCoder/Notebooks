{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional variances for tree based methods using weights on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Uses the approach as described in http://arxiv.org/pdf/1211.0906v2.pdf\n",
    "from skopt.learning import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_variance(y, weights=None):\n",
    "    w_mean = np.average(y, weights=weights)\n",
    "    return np.sum(weights * (y - w_mean)**2) / np.sum(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = make_regression(random_state=0, n_samples=500, n_features=100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtr = DecisionTreeRegressor(max_depth=5, random_state=0)\n",
    "dtr.fit(X_train, y_train)\n",
    "mean = dtr.predict(X_test)\n",
    "var = dtr.tree_.impurity[dtr.apply(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_training_data(X_train, X_test, estimator, weights=None):\n",
    "    \"\"\"\n",
    "    Return weights on y_train for a single tree\n",
    "    as given by formula 4] in \n",
    "    http://www.jmlr.org/papers/volume7/meinshausen06a/meinshausen06a.pdfn http://www.jmlr.org/papers/volume7/meinshausen06a/meinshausen06a.pdf\n",
    "    \n",
    "    For an ensemble it might be useful to set the weights as the cumulative sum\n",
    "    of the weights across all previous trees.\n",
    "    \"\"\"\n",
    "    train_leaf_nodes = estimator.apply(X_train)\n",
    "    test_leaf_nodes = estimator.apply(X_test)\n",
    "\n",
    "    if weights is None:\n",
    "        weights = np.zeros((X_test.shape[0], X_train.shape[0]))\n",
    "    for X_ind, leaf_node in enumerate(test_leaf_nodes):\n",
    "        samples_in_tree_mask = train_leaf_nodes == leaf_node\n",
    "        weights[X_ind][samples_in_tree_mask] += 1.0 / np.sum(samples_in_tree_mask)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = weights_training_data(X_train, X_test, dtr)\n",
    "also_mean = np.zeros(X_test.shape[0])\n",
    "also_var = np.zeros(X_test.shape[0])\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    also_mean[i] = np.average(y_train, weights=weights[i])\n",
    "    also_var[i] = weighted_variance(y_train, weights[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.allclose(mean, also_mean))\n",
    "print(np.allclose(var, also_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state=0, n_estimators=100, max_depth=5, bootstrap=False)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_mean, rf_std = rf.predict(X_test, return_std=True)\n",
    "rf_var = rf_std**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = np.zeros((X_test.shape[0], X_train.shape[0]))\n",
    "also_rf_mean = np.zeros(X_test.shape[0])\n",
    "also_rf_var = np.zeros(X_test.shape[0])\n",
    "\n",
    "tree = rf.estimators_[0]\n",
    "tree.predict(X_test)\n",
    "\n",
    "for tree in rf.estimators_:\n",
    "    weights = weights_training_data(X_train, X_test, tree, weights=weights)\n",
    "    \n",
    "weights /= len(rf.estimators_)\n",
    "for i in range(X_test.shape[0]):\n",
    "    also_rf_mean[i] = np.average(y_train, weights=weights[i])\n",
    "    also_rf_var[i] = weighted_variance(y_train, weights[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.allclose(rf_mean, also_rf_mean))\n",
    "print(np.allclose(rf_var, also_rf_var))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
